{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root dir:  /Users/user010/Desktop/Programming/ML/STS\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "root_dir = os.path.abspath('..')\n",
    "print(\"Root dir: \", root_dir)\n",
    "sys.path.append(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"dataset\": \"stacktraces_hf\",\n",
      "  \"save_dataset\": \"sts_traces\",\n",
      "  \"model\": \"mini_lm\",\n",
      "  \"scores\": {\n",
      "    \"file\": 0.15,\n",
      "    \"func\": 0.15,\n",
      "    \"edit\": 0.1,\n",
      "    \"msg\": 0.2,\n",
      "    \"err\": 0.4\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from utils.helpers import read_config, print_config\n",
    "import numpy as np\n",
    "\n",
    "glob_cfg = read_config(\"../config.yaml\")\n",
    "cfg = read_config(glob_cfg.configs.scoring)\n",
    "\n",
    "print_config(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /Users/user010/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from huggingface_hub import login\n",
    "\n",
    "read_token = os.environ[\"HUGGING_FACE_HUB_TOKEN_READ\"]\n",
    "\n",
    "login(token=read_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: {'path': 'under-tree/stacktrace_dataset'}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset_params = glob_cfg.datasets[cfg.dataset].hf_params\n",
    "print(\"Params:\", dataset_params)\n",
    "dataset = load_dataset(**dataset_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered out 0 examples\n",
      "Dataset size: 248671\n"
     ]
    }
   ],
   "source": [
    "# filter out the examples that have empty trace_list\n",
    "n_before = len(dataset['train'])\n",
    "dataset = dataset.filter(lambda x: len(x[\"trace_list\"]))\n",
    "n_after = len(dataset['train'])\n",
    "print(f\"Filtered out {n_before - n_after} examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['url', 'interpreter', 'stack_trace', 'trace_list', 'error_type', 'error_msg'],\n",
       "    num_rows: 248671\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset[\"train\"]\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: {'model': {'pretrained_model_name_or_path': 'sentence-transformers/paraphrase-MiniLM-L6-v2'}, 'tokenizer': {'pretrained_model_name_or_path': 'sentence-transformers/paraphrase-MiniLM-L6-v2'}}\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "params = glob_cfg.models[cfg.model].hf_params\n",
    "print(\"Params:\", params)\n",
    "tokenizer = AutoTokenizer.from_pretrained(**params.tokenizer)\n",
    "model = AutoModel.from_pretrained(**params.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.14089230448007584\n",
      "Trace 1\n",
      "[\n",
      "  {\n",
      "    \"file_name\": \"/usr/lib/python2.7/dist-packages/nose/case.py\",\n",
      "    \"func_name\": \"runTest\",\n",
      "    \"line_num\": 197\n",
      "  },\n",
      "  {\n",
      "    \"file_name\": \"/\\u00abPKGBUILDDIR\\u00bb/build/lib.linux-aarch64-2.7/matplotlib/testing/decorators.py\",\n",
      "    \"func_name\": \"wrapped_function\",\n",
      "    \"line_num\": 118\n",
      "  },\n",
      "  {\n",
      "    \"file_name\": \"/\\u00abPKGBUILDDIR\\u00bb/build/lib.linux-aarch64-2.7/matplotlib/tests/test_image.py\",\n",
      "    \"func_name\": \"test_cursor_data\",\n",
      "    \"line_num\": 183\n",
      "  }\n",
      "]\n",
      "Trace 2\n",
      "[\n",
      "  {\n",
      "    \"file_name\": \"/home/clq/code/ObjectDetection/detectron/tools/train_net.py\",\n",
      "    \"func_name\": \"create_model\",\n",
      "    \"line_num\": 212\n",
      "  },\n",
      "  {\n",
      "    \"file_name\": \"/home/clq/software/anaconda2/envs/caffe2_py27/lib/python2.7/site-packages/caffe2/python/workspace.py\",\n",
      "    \"func_name\": \"RunNetOnce\",\n",
      "    \"line_num\": 234\n",
      "  },\n",
      "  {\n",
      "    \"file_name\": \"/home/clq/software/anaconda2/envs/caffe2_py27/lib/python2.7/site-packages/caffe2/python/workspace.py\",\n",
      "    \"func_name\": \"CallWithExceptionIntercept\",\n",
      "    \"line_num\": 213\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from utils.auto_similarity import Scorer\n",
    "import json\n",
    "scorer = Scorer(config=cfg, tokenizer=tokenizer, model=model)\n",
    "\n",
    "obj1 = dataset[np.random.randint(0, len(dataset))]\n",
    "obj2 = dataset[np.random.randint(0, len(dataset))]\n",
    "\n",
    "\n",
    "score = scorer.calculate_trace_score(obj1, obj2)\n",
    "\n",
    "print(\"Score:\", score)\n",
    "\n",
    "print(\"Trace 1\")\n",
    "last_five_a = obj1['trace_list'][-3:]\n",
    "print(json.dumps(last_five_a, indent=2))\n",
    "\n",
    "print(\"Trace 2\")\n",
    "last_five_b = obj2['trace_list'][-3:]\n",
    "print(json.dumps(last_five_b, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16368641853332522\n",
      "Score: 0.2502129957079888\n",
      "Trace 1\n",
      "[\n",
      "  {\n",
      "    \"file_name\": \"/home/test/.local/lib/python3.7/site-packages/meshio/_ply.py\",\n",
      "    \"func_name\": \"read_buffer\",\n",
      "    \"line_num\": 102\n",
      "  },\n",
      "  {\n",
      "    \"file_name\": \"/home/test/.local/lib/python3.7/site-packages/meshio/_ply.py\",\n",
      "    \"func_name\": \"_read_binary\",\n",
      "    \"line_num\": 240\n",
      "  },\n",
      "  {\n",
      "    \"file_name\": \"/home/test/.local/lib/python3.7/site-packages/meshio/_ply.py\",\n",
      "    \"func_name\": \"<listcomp>\",\n",
      "    \"line_num\": 240\n",
      "  }\n",
      "]\n",
      "Trace 2\n",
      "[\n",
      "  {\n",
      "    \"file_name\": \"/usr/local/lib/python3.5/dist-packages/sanic/server.py\",\n",
      "    \"func_name\": \"data_received\",\n",
      "    \"line_num\": 144\n",
      "  },\n",
      "  {\n",
      "    \"file_name\": \"httptools/parser/parser.pyx\",\n",
      "    \"func_name\": \"httptools.parser.parser.HttpParser.feed_data (httptools/parser/parser.c:2721)\",\n",
      "    \"line_num\": 171\n",
      "  }\n",
      "]\n",
      "Error type 1: KeyError\n",
      "Error type 2: httptools.parser.errors.HttpParserCallbackError\n",
      "Error msg 1: 'int'\n",
      "Error msg 2: the on_headers_complete callback failed\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "\n",
    "# Convert traces to text\n",
    "id1, id2 = np.random.randint(0, len(dataset), size=2, dtype=int)\n",
    "id1, id2 = int(id1), int(id2)\n",
    "trace1 = dataset[id1]\n",
    "trace2 = dataset[id2]\n",
    "\n",
    "score = scorer.get_full_score(trace1, trace2)\n",
    "\n",
    "print(\"Score:\", score)\n",
    "\n",
    "n = 3\n",
    "last_n1 = trace1['trace_list'][-n:]\n",
    "last_n2 = trace2['trace_list'][-n:]\n",
    "\n",
    "print(\"Trace 1\")\n",
    "print(json.dumps(last_n1, indent=2))\n",
    "\n",
    "print(\"Trace 2\")\n",
    "print(json.dumps(last_n2, indent=2))\n",
    "\n",
    "print(\"Error type 1:\", trace1['error_type'])\n",
    "print(\"Error type 2:\", trace2['error_type'])\n",
    "\n",
    "print(\"Error msg 1:\", trace1['error_msg'])\n",
    "print(\"Error msg 2:\", trace2['error_msg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "n_group = 6000 # cfg.n_group\n",
    "\n",
    "t_low, t_high = 0.33, 0.67\n",
    "\n",
    "groups = {\n",
    "    \"low\": [],\n",
    "    \"mid\": [],\n",
    "    \"high\": []\n",
    "}\n",
    "\n",
    "def condition():\n",
    "    for gr in groups.values():\n",
    "        if len(gr) < n_group:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def gen_pair(dataset):\n",
    "    idx1, idx2 = np.random.randint(0, len(dataset), size=2)\n",
    "    idx1, idx2 = int(idx1), int(idx2)\n",
    "    obj_a, obj_b = dataset[idx1], dataset[idx2]\n",
    "    return obj_a, obj_b\n",
    "\n",
    "def choose_group(score):\n",
    "    if score < t_low:\n",
    "        return \"low\"\n",
    "    elif score < t_high:\n",
    "        return \"mid\"\n",
    "    return \"high\"\n",
    "\n",
    "bar = tqdm(total=n_group, desc=\"Generating pairs (high)\")\n",
    "while condition():\n",
    "    obj_a, obj_b = gen_pair(dataset)\n",
    "    score = scorer.get_full_score(obj_a, obj_b)\n",
    "    group_name = choose_group(score)\n",
    "    if group_name == \"high\": bar.update(1)\n",
    "    if len(groups[group_name]) < n_group:\n",
    "        groups[group_name].append((obj_a, obj_b, float(score[0])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.groups_path = \"groups.json\"\n",
    "with open(cfg.groups_path, 'w') as f:\n",
    "    json.dump(groups, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split to train and val\n",
    "\n",
    "groups_val = {}\n",
    "groups_train = {}\n",
    "for name, group in groups.items():\n",
    "    groups_val[name] = group[:n_group//6]\n",
    "    groups_train[name] = group[n_group//6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_obj_to_dict(obj):\n",
    "    text1 = obj[0]['stack_trace']\n",
    "    text2 = obj[1]['stack_trace']\n",
    "    score = obj[2]\n",
    "    return {\n",
    "        \"text1\": text1,\n",
    "        \"text2\": text2,\n",
    "        \"score\": score\n",
    "    }\n",
    "\n",
    "list_val = sum(groups_val.values(), [])\n",
    "list_train = sum(groups_train.values(), [])\n",
    "\n",
    "list_val = list(map(group_obj_to_dict, list_val))\n",
    "list_train = list(map(group_obj_to_dict, list_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text1', 'text2', 'score'],\n",
       "    num_rows: 3000\n",
       "})"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import DatasetDict, Dataset\n",
    "\n",
    "# dataset from list of dicts\n",
    "ds_val = Dataset.from_list(list_val)\n",
    "ds_train = Dataset.from_list(list_train)\n",
    "ds_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f5aeadb99134dfbb3870751e098680d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2084a21260ff4e3d9930e539b74480b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/15 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad93e6121d0c4efeba08fd9f46adc521",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e0a7b9e9df64a0bad14b64e93895a0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_final = DatasetDict({\n",
    "    \"train\": ds_train,\n",
    "    \"val\": ds_val\n",
    "})\n",
    "ds_final.push_to_hub(cfg.save_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
